---
output:
  html_document: default
  word_document: default
  pdf_document: default
---

## Capstone Project Proposal
###### *Introduction to flow Data Science by Springboard*
### Network Data Flow analysis
##### By Gabriel Fontenot
***

```{r setup, include=FALSE}
# knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

### The problem statement

Network engineers have been collecting flow data for decades regarding performance and behavior. The flow data sets collected include but not limited to device configurations, syslog (device messaging), and device snmptraps (fault management). Engineers and operations have for the most part used the collected flow data to assist with various troubleshooting and design exercizes. Using the statistical and proablitity modules along with visualizations techniques, the idea is to enhance the overall flow data analization experience and provide a conceise and targeted approach to understanding network and application behavior.

### The flow data set

The flow data sets subject to flow data analysis include a packet capture of network behavior (who is talking to who) and a description of the host communicating on the network. The network flow data includes source and destination ip addresses along with host descriptions to assist in identifying traffic patterns and anomolies.

The intended flow data set has the following structure.

1) No.                     : int
2) Time                    : num
3) Source                  : Factor
4) Destination             : Factor
5) Protocol                : Factor
6) Length                  : int
7) Info                    : chr
8) hostname                : Factor
9) last_registration_req_at: int
10) platform                : Factor
11) total_flows             : int
12) cpu_load                : num
13) current_sw_version      : Factor
14) created_at              : int
15) enable_pid_lookup       : logic

Please see the decriptions below for additional field details and usage:

- The column 'Time' denotes the time starting at time 0 at which the packet capture started, with each time interval is recored up to 6 decimal places.

- The column 'Source' denotes the source IP ADDRESS of the host that initiated the flow.

- The column 'Destination' denotes the destination IP ADDRESS of the host of which the source is communicating with.

- The column 'Protocol' denotes the IP protocol used for the current flow.

- The column 'Length' denotes the overall lenght of the packet captured for the current flow.

- The column 'Info' describes the current flow state and provides additional flow details.

- The column 'hostname' reflects the current host name configured on the guest OS.

- The column 'last_registration_req_at' denotes the last time the host checked in.

- The column 'platform' denotes the guest OS host distribution.

- The column 'total_flows' denotes the number of flows detected during the communication period.

- The column 'cpu_load' describes the overall behavior of the guest OS CPU during the flow.

- The column 'current_sw_version' describes the current agent version as installed on the host.

- The column 'created_at' denotes the time period the agent was installed.

- The column 'enable_pid_lookup' denotes the status of the PID lookup functionality on the host.

# Evaluating the flow data

### RStudio Libraries

The libraries listed below are utilized to provide functionality required to parse, analyze and display the appropriate flow data sets.

```{r library, include=TRUE, message=FALSE}

library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library("rjson")
```

### Loading the data set

The 'csv' file representing the flow analysis is loaded into the variable flowData. The data is comprised of a network capture of multiple host communicating on the network. 

```{r load_flows, include=FALSE}
fileName <- "smallFlows_clean.csv"
flowData = read.csv(fileName, header = TRUE)
```

### Counting records and variables

Using R methods and functionality, determine various flow data set counts. Counting various aspects of your flow data set can prepare you for dealing with the content during analysis.

* Count the number of rows and columns in the flow data set, `r fileName`.

```{r count_rows, include=FALSE}
row_count <- nrow(flowData)
col_count <- ncol(flowData)
sprintf("There are a total of %s ROWs and %s COLUMNs in the flow data set.", row_count, col_count)
```

* Count the number of rows in the flow data set that have a platform of "CentOS-6.5"

```{r count_rows_platform, include=FALSE}

count_filter <- nrow(filter(flowData, platform == "CentOS-6.5"))

sprintf("There are a total of %s ROWs in the flow data se that contain the name 'CentOS-6.5'.", count_filter)
```

### Data trends and anomolies

Using the flow data set, we can get an idea of the guest OS distribution accross the collected flows. Using the output we can isolate various flow data points. One such flow data point can be the number of guest OS distributions that are commonly deployed vs. distributions that are not heavly utilized.

```{r trends_anomalies, include=TRUE, message=FALSE, fig.align='center'}
number_ticks <- function(n) {function(limits) pretty(limits, n)}
  
a <- flowData %>% group_by(platform) %>% tally

ggplot(a, aes(x=platform, y=n)) + 
  geom_point(na.rm=TRUE, aes(colour = platform)) +
  scale_y_continuous(breaks=number_ticks(10)) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

The point plot above shows CentOS-6.5 as the most popular OS deployed with RedHatEnterpriseServer-7.2 and MSServer2012R2Standard making up the middle tier OS's. 

Note: The chart can also assist in tracking host OS point specific distributions. 

### Using histogram

As we explore the flow data set further, we can evaluate the packet size per host OS distriburtion. This may be an indication of how much traffic each OS type averages accross the network.

```{r bar_plot_histogram, include=TRUE, message=FALSE, fig.align='center'}

ggplot(flowData,aes(x=Length, group=platform,fill=platform)) +
  geom_histogram(na.rm=TRUE, position="dodge", binwidth=500) + 
  theme_bw()
```

###  Compaing Quantities

Using the flow data set, let's compare the protocol distribution over the collected time interval. In looking at the overall Time selection, lets focus on the time slot between and including minute 235 through min 240.

```{r compare_quantities, include=TRUE, message=FALSE, fig.align='center'}

ggplot(flowData, aes(x=Time, colour=Protocol, fill=Protocol)) + 
  geom_density(alpha = 0.1, na.rm=TRUE,) +
  xlim(235, 240)
```

The output above provides an insite into the more prevalant traffic during the selected time interval. It is clear during this time 'DB-LSP-DISC' more than dobuled the the usage of the other protocols present on the network at the given time.

### Using Scatterplots

Using the give data set, let's understand the packet distribution per Protocol. The analysis provides insight into the host packect sizes observed on the network during the packet collection.

```{r test, include=TRUE, message=FALSE, fig.align='center'}

# geom_point(aes(colour = factor(source)), size = 4)

ggplot(flowData, aes(Length, Protocol)) + 
  geom_point(aes(colour = Protocol), na.rm=TRUE) +
  scale_x_continuous(breaks=number_ticks(20)) + 
  theme(legend.position="none")
```

Using the give data set, let's understand the packet distribution per operating system. The analysis provides insight into the host packect sizes observed on the network during the packet collection.

```{r scatterplot, include=TRUE, message=FALSE, fig.align='center'}

ggplot(flowData, aes(x = Length, y = platform, colour = cond)) + 
  geom_point(na.rm=TRUE, aes(colour = platform)) +
  scale_x_continuous(breaks=number_ticks(20)) + 
  theme(legend.position="none")
```

From the above data analysis, we can visualize the distribtuion and note the behavior of the hosts that are not evenly distributed. Further analysis can be acheived to understand why some host guest OS's have different packet distributions.

### Using Time Series Plot

Using the defined data set, let's further evealute the host OS to understnad during the capture interval the usage of the network. This can be accomplished by plotting the flows over time.

```{r time_series_plot1, include=TRUE, message=FALSE, fig.align='center'}

# created_at
# last_registration_req_at

ggplot(flowData, aes(x=as.POSIXct(last_registration_req_at, origin="1970-01-01"), y=platform,)) + 
  geom_point(na.rm=TRUE, aes(colour = platform)) + 
  theme(legend.position="none")
```

The output above highlights the time periods that host last registered. From the output we can see that where is one anomoly where as CentOS-6.5 checks in on a different interval.

```{r time_series_plot2, include=TRUE, message=FALSE, fig.align='center'}

ggplot(flowData, aes(x=Time, y=platform)) + 
  geom_point(na.rm=TRUE, aes(colour = platform)) +
  scale_x_continuous(breaks=number_ticks(20)) + 
  theme(legend.position="none")
```

The output above highlights the traffic patters per host distribution across the collected time interval. While a few hosts communicated throughout the time frame collected, a couple have less time on the network.

### MISC

```{r misc, echo=FALSE, message=FALSE, fig.align='center'}

ggplot(flowData, aes(x=Time, y=platform, color=platform)) +
  geom_boxplot(na.rm=TRUE) +
  scale_x_continuous(breaks=number_ticks(20)) +
  theme(legend.position="none")
```

## Conclusion

To be updated.
