---
output:
  html_document: default
  word_document: default
  pdf_document: default
---

## Capstone Project Proposal
###### *Introduction to flow Data Science by Springboard*
### Network Data Flow analysis
##### By Gabriel Fontenot
***

```{r setup, include=FALSE}
# knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

### The problem statement

Network engineers have been collecting flow data for decades regarding performance and behavior. The flow data sets collected include but not limited to device configurations, syslog (device messaging), and device snmptraps (fault management). Engineers and operations have for the most part used the collected flow data to assist with various troubleshooting and design exercizes. Using the statistical and proablitity modules along with visualizations techniques, the idea is to enhance the overall flow data analization experience and provide a conceise and targeted approach to understanding network and application behavior.

### About the flow/host data set

The flow data sets subject to flow data analysis include a packet capture describing the overall network behavior (who is talking to who) and a description of the host communicating on the network during the specified time interval. The network flow data includes source and destination ip addresses along with host descriptions to assist in identifying traffic patterns and anomolies.

The intended flow data set has the following structures and descriptions.

####Flows

 1)  host_name                 : Factor : the host name of the guest OS
 2)  last_software_update_at   : int    : the last time the host agent was updated
 3)  data_plane_disabled       : logic  : the status of the data plane forwarding
 4)  platform                  : Factor : the guest OS host distribution
 5)  agent_type                : Factor : the current agent deployed on the guest os
 6)  current_sw_version        : Factor : the current agent version as installed on the host
 7)  enable_pid_lookup         : logic  : the current status of the PID lookup functionality
 8)  last_config_fetch_at      : int    : the timeframe the guest OS last checked in
 
####Sensors

 1) start_timestamp           : num    : the timeframe the flow started
 2) src_port                   : int    : the source port for the selected flow
 3) rev_pkts                   : int    : the packet count for the reverse flows
 4) rev_bytes                  : int    : the byte count for the reverse flows
 5) proto                      : Factor : the IP protocol used for the current flow
 6) src_address                : Factor : source IP ADDRESS of the host that initiated the flow
 7) timestamp                  : Factor : the timestamp the flow was collected
 8) fwd_bytes                  : int    : the byte count for the forward direction of the flow
 9) src_hostname               : Factor : the host name of the source host in the flow
 10) dst_address               : Factor : destination IP ADDRESS of the host of which the source is communicating with
 11) src_is_internal           : Factor : the current state of the host relative to is location
 12) dst_port                  : int    : the destination port for teh selected flow
 13) srtt_usec                 : int    : the srtt latency associated with the current flow
 14) vrf_id                    : int    : the vrf id for the current flow
 15) vrf_name                  : Factor : the vrf name for the current flow
 16) fwd_pkts                  : int    : the packet count for the forward direction of the flow
 17) server_app_latency_usec   : int    : the application latency as derived from the application agent
 18) total_network_latency_usec: int    : the calculated network latency
 19) total_pkts                : int    : the total fwd and rev packet count
 20) platform_windowns         : logic  : the state of the platform, windows
 21) total_bytes               : int    : the toal fwd and rev byte count

# Evaluating the flow data

### RStudio Libraries

The libraries listed below are utilized to provide functionality required to parse, analyze and display the appropriate flow data sets.

```{r library, include=TRUE, message=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(rjson)
```

### Loading the data sets

The 'csv' files representing the flow analysis are loaded into the variable flowData and SensorData. The data is comprised of a network capture of multiple host communicating on the network during the define collection period. 

```{r load_flows, include=FALSE}
fileName <- "FlowData.csv"
flowData = read.csv(fileName, header = TRUE)

fileName <- "SensorData.csv"
sensorData = read.csv(fileName, header = TRUE)
```

### Cleaning the flow/host data sets

The prepare the data for analysis, the data must first be normalized. The multiple step process includes the following steps.

1) Remove ROWs with non IPv4 addresses in Source and Destination

  The collected data set contains IPv4 and IPv6 addresses. For the purpuse of this exercise, all IPv6 addresses will be removed.

```{r retain_ipV4, include=FALSE}
flowData <- flowData %>% 
  filter(str_detect(src_address, ".*?(\\d+\\.\\d+\\.\\d+\\.\\d+).*?")) %>%
  filter(str_detect(dst_address, ".*?(\\d+\\.\\d+\\.\\d+\\.\\d+).*?"))
```

2) Remove ROWs with no destination HOSTNAME

  The collected data set contains hosts without a defined hostname. These flows will be identified and removed from the analysis   as they are flows that do not contain agents.

```{r remove_empty_hostnames, include=FALSE}
flowData <- with(flowData, flowData[!(dst_hostname == "" | is.na(dst_hostname)), ])
```

3) Merge data sets, flows and hosts

  To getter a holistic view of the flows, the flow data and the host data will be combined. This effort will allow for        additional oppurtunities to corelate flow and host data.

```{r merge_data_sets, include=FALSE}
data <- merge(sensorData, flowData, by.x=c('host_name'), by.y=c('dst_hostname'))
```

4) Add new column Total Packet

  To provide summarization for the packet count, a sumamry field of the fwd and rev packets will be added.

```{r add_total_packet, include=FALSE}
data$total_pkts <- data$rev_pkts + data$fwd_pkts
```

5) Add new column Total Bytes

  To provide summarization for the byte count, a sumamry field of the fwd and rev bytes will be added.

```{r add_total_bytes, include=FALSE}
data$total_bytes <- data$rev_bytes + data$fwd_bytes
```

6) Add new column Windows

```{r add_windows, include=FALSE}
data <- data %>% 
  mutate(platform_windowns = ifelse(str_detect(platform, ".*?(^MS.+).*?"), TRUE, FALSE))
```

7) Create a cleaned CSV file representing the data to be analyzed.

  The cleaned data will be saved into a CSV file callsed flowDataSensor_clean.

```{r create_csv, include=FALSE}
write.csv(data, file = "flowDataSensor_clean.csv")
```

### Counting records and variables

Using R methods and functionality, determine various flow data set counts. Counting various aspects of your flow data set can prepare you for dealing with the content during analysis.

* Count the number of rows and columns in the flow data set, `r fileName`.

```{r count_rows, include=FALSE}
row_count <- nrow(data)
col_count <- ncol(data)
sprintf("There are a total of %s ROWs and %s COLUMNs in the flow data set.", row_count, col_count)
```

* Count the number of rows in the flow data set that have a platform of "CentOS-6.5"

```{r count_rows_platform, include=FALSE}

count_filter <- nrow(filter(data, platform == "CentOS-6.5"))

sprintf("There are a total of %s ROWs in the flow data se that contain the name 'CentOS-6.5'.", count_filter)
```

### Data trends and anomolies

Using the flow data set, we can get an idea of the guest OS distribution accross the collected flows. Using the output we can isolate various flow data points. One such flow data point can be the number of guest OS distributions that are commonly deployed vs. distributions that are not heavly utilized.

```{r trends_anomalies, include=TRUE, message=FALSE, fig.align='center'}
number_ticks <- function(n) {function(limits) pretty(limits, n)}
  
a <- data %>% group_by(platform) %>% tally

ggplot(a, aes(x=platform, y=n)) + 
  geom_point(na.rm=TRUE, aes(colour = platform)) +
  scale_y_continuous(breaks=number_ticks(10)) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

The point plot above shows CentOS-6.5 as the most popular OS deployed with RedHatEnterpriseServer-7.2 and MSServer2012R2Standard making up the middle tier OS's. 

Note: The chart can also assist in tracking host OS point specific distributions. 

### Using histogram

As we explore the flow data set further, we can evaluate the packet size per host OS distriburtion. This may be an indication of how much traffic each OS type averages accross the network.

```{r bar_plot_histogram, include=TRUE, message=FALSE, fig.align='center'}

data %>% ggplot(aes(x=dst_port, color=platform, fill=platform)) +
  geom_histogram(na.rm=TRUE) +  
  theme_bw()

```

###  Compaing Quantities

Using the flow data set, let's compare the protocol distribution over the collected time interval. In looking at the overall Time selection, lets focus on the time slot between and including minute 235 through min 240.

ex. xlim(235, 240)
  
```{r compare_quantities, include=TRUE, message=FALSE, fig.align='center'}

ggplot(data, aes(x=timestamp, colour=proto, fill=proto)) + 
  geom_density(alpha = 0.1, na.rm=TRUE,)  +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

The output above provides an insite into the more prevalant traffic during the selected time interval. It is clear during this time 'DB-LSP-DISC' more than dobuled the the usage of the other protocols present on the network at the given time.

### Using Scatterplots

Using the give data set, let's understand the packet distribution per Protocol. The analysis provides insight into the host packect sizes observed on the network during the packet collection.

```{r test, include=TRUE, message=FALSE, fig.align='center'}

# geom_point(aes(colour = factor(source)), size = 4)

ggplot(data, aes(proto, total_pkts)) + 
  geom_point(aes(colour = proto), na.rm=TRUE) + 
  theme(legend.position="none")
```

Using the give data set, let's understand the packet distribution per operating system. The analysis provides insight into the host packect sizes observed on the network during the packet collection.

```{r scatterplot, include=TRUE, message=FALSE, fig.align='center'}

ggplot(data, aes(x = start_timestamp, y = total_pkts)) + 
  geom_point(na.rm=TRUE, aes(color = platform))
```

From the above data analysis, we can visualize the distribtuion and note the behavior of the hosts that are not evenly distributed. Further analysis can be acheived to understand why some host guest OS's have different packet distributions.

### Using Time Series Plot

Using the defined data set, let's further evealute the host OS to understnad during the capture interval the usage of the network. This can be accomplished by plotting the flows over time.

```{r time_series_plot1, include=TRUE, message=FALSE, fig.align='center'}

# created_at
# last_registration_req_at

ggplot(data, aes(x=as.POSIXct(last_config_fetch_at, origin="1970-01-01"), y=platform,)) + 
  geom_point(na.rm=TRUE, aes(colour = platform)) + 
  theme(legend.position="none")
```

The output above highlights the time periods that host last registered. From the output we can see that where is one anomoly where as CentOS-6.5 checks in on a different interval.

```{r time_series_plot2, include=TRUE, message=FALSE, fig.align='center'}

ggplot(data, aes(x=start_timestamp, y=platform)) + 
  geom_point(na.rm=TRUE, aes(colour = platform)) +
  theme(legend.position="none")
```

The output above highlights the traffic patters per host distribution across the collected time interval. While a few hosts communicated throughout the time frame collected, a couple have less time on the network.

### MISC

```{r misc, echo=FALSE, message=FALSE, fig.align='center'}

ggplot(data, aes(x=start_timestamp, y=platform, color=platform)) +
  geom_boxplot(na.rm=TRUE) +
  scale_x_continuous(breaks=number_ticks(20)) +
  theme(legend.position="none",
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

```{r time_series_plot3, include=TRUE, message=FALSE, fig.align='center'}

ggplot(data, aes(x=src_port, y=dst_port, text = paste("platform:",platform))) + 
  geom_point(na.rm=TRUE, aes(colour = proto)) +
  ylim(50, 90)

```

```

## Conclusion

To be updated.
